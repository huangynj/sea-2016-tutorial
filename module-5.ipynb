{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "<p style=\"float:right\">\n",
    "<img src=\"images/logos/cu.png\" style=\"display:inline\" />\n",
    "<img src=\"images/logos/cires.png\" style=\"display:inline\" />\n",
    "<img src=\"images/logos/nasa.png\" style=\"display:inline\" />\n",
    "</p>\n",
    "\n",
    "# Python, Jupyter & pandas: Module 5\n",
    "\n",
    "## Inference and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Let's create some other graphs from the data we looked at in the previous module.\n",
    "\n",
    "_**Note**: The .csv read by the next cell should have been created by the Module 4 notebook. Please be sure you have evaluated that notebook before proceeding._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "monthly = pd.read_csv('monthly-extents.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We're going to look for a trend in the Northern Hemisphere June snowcover.\n",
    "\n",
    "First, we'll create a new DataFrame indexed by years, with a column for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "year_by_month = monthly.set_index([monthly.index.year, monthly.index.month]).unstack(1)\n",
    "year_by_month.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the overall mean for June snow cover, and graph each year's difference from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "june_anomalies = year_by_month['snowcover'][6] - year_by_month['snowcover'][6].mean()\n",
    "june_anomalies = june_anomalies.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context(rc={'figure.figsize': (15, 4)}):\n",
    "    june_anomalies.plot(title='Northern Hemisphere Snow Cover Anomalies: June',kind='bar', color='r')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Compute a least squares linear fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "slope, intercept = np.polyfit(june_anomalies.index.values, june_anomalies.values, 1)\n",
    "fit_function = np.poly1d([ slope, intercept])\n",
    "best_fit = fit_function(june_anomalies.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context(rc={'figure.figsize': (15, 4)}):\n",
    "    june_anomalies.plot(title='Northern Hemisphere Snow Cover Anomalies: June',kind='Bar', color='r')\n",
    "    plt.plot(best_fit, color='b', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use [Plotly](https://plot.ly/) to create an interactive graph to more closely examine the anomaly values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotly's API is very declarative. Here, we'll use some of the basic settings to create a graph similar to the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snow_cover_anomalies = go.Bar(\n",
    "    # data\n",
    "    x=june_anomalies.index,\n",
    "    y=june_anomalies,\n",
    "    \n",
    "    # style\n",
    "    name='Anomaly',\n",
    "    marker={\n",
    "        'color': 'red'\n",
    "    },\n",
    "    hoverinfo='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snow_cover_trend = go.Scatter(\n",
    "    # data\n",
    "    x=june_anomalies.index,\n",
    "    y=best_fit,\n",
    "    \n",
    "    # style\n",
    "    name='Best Fit',\n",
    "    line ={\n",
    "        'dash': 8,\n",
    "        'color': 'blue'\n",
    "    },\n",
    "    hoverinfo='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    title='Northern Hemisphere Snow Cover Anomalies: June',\n",
    "    xaxis={\n",
    "        'tickmode': 'linear',\n",
    "        'dtick': 5,\n",
    "        'showline': True,\n",
    "        'showgrid': True\n",
    "    },\n",
    "    yaxis={\n",
    "        'showline': True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = go.Data([snow_cover_anomalies, snow_cover_trend])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure = go.Figure({'data': data, 'layout': layout})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can hover to see the precise data values, click on the legend to show/hide graph objects, click and drag to zoom in various areas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotly.offline.iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "# [xarray](http://xarray.pydata.org/en/stable/)\n",
    "\n",
    "     \"xarray (formerly xray) is an open source project and Python package\n",
    "     that aims to bring the labeled data power of pandas to the physical\n",
    "     sciences, by providing N-dimensional variants of the core pandas data\n",
    "     structures.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "With xarray you can open a NetCDF file as an `xarray.Dataset` and a lot of the grunt work of setting up dimensions and converting axes is done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import xarray as xr  # import as xr by convention\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Attach a dataset variable to the NetCDF endpoint or file with `xarray.open_dataset()`.\n",
    "\n",
    "`snowcover_url` can be either a NetCDF file or a NetCDF endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# unzip packaged data file \n",
    "!cd data; unzip -o nhsce_v01r01_19661004_20160201.nc.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# if you want to read from the DODs/OPeNDAP NetCDF endpoint:\n",
    "# snowcover_url = 'http://www.ncdc.noaa.gov/thredds/dodsC/cdr/snowcover/nhsce_v01r01_19661004_latest.nc'\n",
    "\n",
    "snowcover_file = 'data/nhsce_v01r01_19661004_20160201.nc'\n",
    "dataset = xr.open_dataset(snowcover_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "# Fix this to read a local file?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "You can see the dataset's dimensions attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dataset.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "and the indexes attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dataset.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Notice xarray has already taken care of converting the time coordinate into a `DatetimeIndex` (as opposed to how we handled it by hand in module-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "List the dataset's variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dataset.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We can access the variables as attributes or dictionary keys.\n",
    "\n",
    "Accessing a `DataSet` attribute yields a `DataArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dataset['land']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "So just like in Module-4, we have access to all of the data and indexes from the endpoint/file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Let's look at the `DataArray` for Snow Cover Extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "snow_cover_extent = dataset['snow_cover_extent']\n",
    "print(snow_cover_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Note the second line of output.\n",
    "\n",
    "> `[19933056 values with dtype=float64]`\n",
    "\n",
    "\n",
    "This indicates the operation of\n",
    "downloading the data has been deferred; that is, we have not fetched all of\n",
    "the values from the endpoint, just the metadata, which is being\n",
    "displayed.  If you've accessed the `.values` or `.data` attributes, you will\n",
    "have downloaded the data and you will see a printed representation of the\n",
    "`numpy.ndarray`.\n",
    "\n",
    "This defered downloading allows you to work with just the data you are\n",
    "interested in, without having to download an entire file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## You can access data in `DataArray`s a number of ways.\n",
    "\n",
    "By indexing positionally by integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snow_cover_extent[2401]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "You can see the order of the dimensions, and subset accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "print(snow_cover_extent.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "a_slice = snow_cover_extent[2400:2403, 30:35, 35:41]\n",
    "print(a_slice.shape)\n",
    "print(a_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "And you can see again, this operation to retrieve `a_slice` has retrieved only the data necessary from the remote file or endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "print(snow_cover_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "You can also grab a slice by integer along a named index with `DataArray.isel`  (*isel* => for integer select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "snow_cover_extent.isel(rows=slice(30, 40, 2), time=slice(970, 972), cols=slice(40, 45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Or you can use slices of an index's native type `DataArray.sel`  (in this case, the date strings are coerced to numpy.datetime64 objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "snow_cover_extent.sel(time=slice('2010-01-01', '2011-01-02'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fetching all of the data is still deferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "print(snow_cover_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Finally, we can use what we know about the data file write a couple of routines\n",
    "to compute anomalies and display them on a map.\n",
    "\n",
    "We can use the `DataSet.groupby` function to gather groups of time dimensions\n",
    "like in module-4.  Here, we will group all of the time index values by the month\n",
    "number.  Accessing the `groups` attribute returns a dictionary where the keys are\n",
    "months, and the values are a list of indices into the dataset time index for that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "month_indices = dataset.groupby('time.month').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Keys:\", month_indices.keys(), \"  One for each month\")\n",
    "print(\"Feburary Indices:\", month_indices[2][0:5], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We can use a list of indices to select data with `isel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "month_num = 6\n",
    "\n",
    "weeks = dataset['time'].isel(time=month_indices[month_num])\n",
    "\n",
    "print(\"first 10 DataSet['Time'] Values:\\n \", weeks.values[0:10])\n",
    "print(\"\\nTotal number of elements in month_indices\", len(weeks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We will use every available measurement in the `DataSet` to compute a median snow cover for a given month.\n",
    "\n",
    "We do this by computing a mean across time for each of the month's samples. This gives us a fracional probability of any measurement having snow cover or not.  By taking those values that are greater than or equal to .5, we get a median snow cover for the month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Choose a month with some snow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "month_number = 2\n",
    "average_snowcover = dataset['snow_cover_extent'].isel(time=month_indices[month_number]).mean(dim='time')\n",
    "median_snowcover = average_snowcover > .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "lats = dataset.latitude.values\n",
    "lons = dataset.longitude.values\n",
    "land = dataset.land.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Create a function that will return a categorical grid of the snow cover anomaly. For each cell, we want to identify whether it is part of the selected month's extent and/or median extent, or if it is land or ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def anomaly_snowcover(selected_snow_cover, median_snowcover, land):\n",
    "    sel = selected_snow_cover.values.astype(bool)\n",
    "    med = median_snowcover.values.astype(bool)\n",
    "    land = land.astype(bool)\n",
    "\n",
    "    # Do logical intersections of the data\n",
    "    both     =  sel &  med\n",
    "    only_med = ~sel &  med\n",
    "    only_sel =  sel & ~med\n",
    "\n",
    "    # Assign a those intersections values.\n",
    "    out = np.zeros_like(land.astype(int))\n",
    "    out[~land] = 0\n",
    "    out[land] = 1\n",
    "    out[both] = 2\n",
    "    out[only_med] = 3\n",
    "    out[only_sel] = 4\n",
    "\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Create a [colormap](http://matplotlib.org/api/colors_api.html?highlight=listedcolormap#matplotlib.colors.ListedColormap) and [normalizer](http://matplotlib.org/users/colormapnorms.html) for plotting the `anomaly_snowcover` output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know our data will only have values 0 through 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Choose some nice colors\n",
    "categorical_cmap = mpl.colors.ListedColormap(colors=['#D4EFFA', '#A3BAA5','#FEFEFE','#BC80BC', '#ACD665' ])\n",
    "\n",
    "# center your bounds around your datapoint.\n",
    "bounds = [-.5, .5, 1.5, 2.5, 3.5, 4.5]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, categorical_cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Now use a widget to plot anomalies of snow cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import calendar as cal\n",
    "\n",
    "def title_function(datetime64ns):\n",
    "    date = datetime64ns.astype('M8[ms]').astype(dt.date)\n",
    "    return \"Snow Cover: {0}-{1} compared to median\".format(cal.month_abbr[date.month], date.year)\n",
    "\n",
    "def selected_month_label(datetime64ns):\n",
    "    date = datetime64ns.astype('M8[ms]').astype(dt.date)\n",
    "    return '{0} {1} Only'.format(cal.month_abbr[date.month], date.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "@interact(index_in=widgets.IntSlider(min=0,max=len(month_indices[month_number])-1,step=1,value=0, continuous_update=False))\n",
    "def plot_anomaly(index_in=0):\n",
    "    index = month_indices[month_number][index_in]\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    m = Basemap(projection='npstere', boundinglat=30, lon_0=-45)\n",
    "    m.drawcoastlines()\n",
    "\n",
    "    parallels = np.arange(0, 90, 20)\n",
    "    m.drawparallels(parallels, labels=[True])\n",
    "    meridians = np.arange(-180, 180, 45)\n",
    "    m.drawmeridians(meridians, labels=[True,True,False,True,True,True,True,True])\n",
    "    \n",
    "    the_data = anomaly_snowcover(dataset['snow_cover_extent'].isel(time=index), median_snowcover, land)\n",
    "    m.pcolor(lons, lats, the_data, latlon=True, cmap=categorical_cmap, norm=norm)\n",
    "    \n",
    "    times = dataset['time'].isel(time=index).values\n",
    "    \n",
    "    cbar = plt.colorbar(ticks=[0, 1, 2, 3, 4], norm=norm)\n",
    "    cbar.set_ticklabels(['Ocean', 'Land', 'Both', 'Median Only', selected_month_label(times)])\n",
    "    plt.title(title_function(times))\n",
    "    plt.draw()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "name": "module-5.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
