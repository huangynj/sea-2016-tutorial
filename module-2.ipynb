{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p style=\"float:right\">\n",
    "<img src=\"images/cu.png\" style=\"display:inline\" />\n",
    "<img src=\"images/cires.png\" style=\"display:inline\" />\n",
    "<img src=\"images/nasa.png\" style=\"display:inline\" />\n",
    "</p>\n",
    "\n",
    "# Python, Jupyter & pandas tutorial: Module 2\n",
    "\n",
    "## Obtaining data and basic inspection\n",
    "\n",
    "### Basic data access\n",
    "\n",
    "It is, of course, possible to obtain data (rougly construed -- we'll look at images here because they're simple to view) externally (or via the `%%script` magic, which saves the trouble of opening a separate terminal / command / browser window). We can fetch an image to the local filesystem, then display it with Markdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2016-03-16 13:53:00--  ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/Feb/N_197902_extn.png\n",
      "           => 'N_197902_extn.png'\n",
      "Resolving sidads.colorado.edu... 128.138.135.20\n",
      "Connecting to sidads.colorado.edu|128.138.135.20|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /DATASETS/NOAA/G02135/Feb ... done.\n",
      "==> SIZE N_197902_extn.png ... 224912\n",
      "==> PASV ... done.    ==> RETR N_197902_extn.png ... done.\n",
      "Length: 224912 (220K) (unauthoritative)\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 22% 33.3M 0s\n",
      "    50K .......... .......... .......... .......... .......... 45% 39.6M 0s\n",
      "   100K .......... .......... .......... .......... .......... 68% 35.0M 0s\n",
      "   150K .......... .......... .......... .......... .......... 91% 54.7M 0s\n",
      "   200K .......... .........                                  100%  179M=0.005s\n",
      "\n",
      "2016-03-16 13:53:00 (42.1 MB/s) - 'N_197902_extn.png' saved [224912]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "rm -f N_197902_extn.png\n",
    "wget ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/Feb/N_197902_extn.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='N_197902_extn.png' style='float:left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also obtain an image directly from the internet and display in with Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/Feb/N_201602_extn.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/Feb/N_201602_extn.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenDAP data access\n",
    "\n",
    "The `netCDF4` package provide OpenDAP client capabilities. Here we use it to obtain data via an OpenDAP server at NSIDC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "url = ('http://opendap.apps.nsidc.org:80/opendap/DATASETS/'\n",
    "       'nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc'\n",
    ")\n",
    "dataset = netCDF4.Dataset(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection\n",
    "\n",
    "We can inspect the `dataset` object to see its class. In this case, it's exactly what we'd expect given that we created it with `netCDF4.Dataset`. However, it's sometimes the case, especially when working with a new library, that we do not anticipate the type of an object returned from some method / function call, so it's handy to be able to find out what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netCDF4._netCDF4.Dataset"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we have a `Dataset` object from the `netCDF4` library, we could of course go consult that library's documentation to learn what kinds of attributes and methods such an object has. Or, we can bravely plunge in and have a look for ourselves. Here, we use Python's built-in `dir` command to get a list of object members. We filter out those whose names begin with `_`, as these are generally not meant to be used directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conventions',\n",
       " 'DODS_EXTRA.Unlimited_Dimension',\n",
       " 'Metadata_Conventions',\n",
       " 'cdm_data_type',\n",
       " 'close',\n",
       " 'cmptypes',\n",
       " 'createCompoundType',\n",
       " 'createDimension',\n",
       " 'createEnumType',\n",
       " 'createGroup',\n",
       " 'createVLType',\n",
       " 'createVariable',\n",
       " 'data_model',\n",
       " 'date_created',\n",
       " 'delncattr',\n",
       " 'dimensions',\n",
       " 'disk_format',\n",
       " 'enumtypes',\n",
       " 'file_format',\n",
       " 'filepath',\n",
       " 'geospatial_lat_max',\n",
       " 'geospatial_lat_min',\n",
       " 'geospatial_lat_units',\n",
       " 'geospatial_lon_max',\n",
       " 'geospatial_lon_min',\n",
       " 'geospatial_lon_units',\n",
       " 'get_variables_by_attributes',\n",
       " 'getncattr',\n",
       " 'groups',\n",
       " 'id',\n",
       " 'institution',\n",
       " 'isopen',\n",
       " 'keepweakref',\n",
       " 'keywords',\n",
       " 'keywords_vocabulary',\n",
       " 'license',\n",
       " 'metadata_link',\n",
       " 'naming_authority',\n",
       " 'ncattrs',\n",
       " 'parent',\n",
       " 'path',\n",
       " 'platform',\n",
       " 'product_version',\n",
       " 'reference',\n",
       " 'renameAttribute',\n",
       " 'renameDimension',\n",
       " 'renameGroup',\n",
       " 'renameVariable',\n",
       " 'sensor',\n",
       " 'set_auto_mask',\n",
       " 'set_auto_maskandscale',\n",
       " 'set_auto_scale',\n",
       " 'set_fill_off',\n",
       " 'set_fill_on',\n",
       " 'setncattr',\n",
       " 'setncatts',\n",
       " 'source',\n",
       " 'spatial_resolution',\n",
       " 'standard_name_vocabulary',\n",
       " 'summary',\n",
       " 'sync',\n",
       " 'title',\n",
       " 'variables',\n",
       " 'vltypes']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "list(filter(lambda x: not re.match('^_.*', x), dir(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this list, some items appear to be metadata, e.g. those starting with `geospatial_`, or `institution` or `platform`. We can look at the name of the dataset via the `title` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MEaSUREs Northern Hemisphere Terrestrial Snow Cover Extent Daily 25km EASE-Grid 2.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refer to [this dataset's documentation](http://nsidc.org/data/docs/measures/nsidc-0530/index.html) for more information about the meaning of these attributes.\n",
    "\n",
    "The actual data is available under `variables`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "rows\n",
      "cols\n",
      "coord_system\n",
      "latitude\n",
      "longitude\n",
      "merged_snow_cover_extent\n",
      "ims_snow_cover_extent\n",
      "passive_microwave_gap_filled_snow_cover_extent\n",
      "modis_cloud_gap_filled_snow_cover_extent\n"
     ]
    }
   ],
   "source": [
    "for variable in dataset.variables:\n",
    "    print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these variables correspond to those listed in Table 3 of the documentation page linked to above.\n",
    "\n",
    "Let's extract the `latitude` variable and look at its properties. In a Jupyter notebook, as in a Python REPL -- but unlike in non-interactive Python code -- simply giving the name of an object will cause its textual representation to be printed. (In a Jupyter notebook, this only works on the last line of a cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 latitude(rows, cols)\n",
       "    _FillValue: -999.0\n",
       "    long_name: latitude of cell center in EASE-Grid-2.0\n",
       "    units: degrees_north\n",
       "    valid_range: [-90.  90.]\n",
       "    standard_name: latitude\n",
       "unlimited dimensions: \n",
       "current shape = (720, 720)\n",
       "filling off"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude = dataset.variables['latitude']\n",
    "latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of useful information! `latitude` is a 720x720 array, with valid values ranging from -90 to 90 degrees north, and invalid (\"fill\") marked as -999.\n",
    "\n",
    "Since we pulled `latitude` out of another object, rather than creating it explicitly as we did with the `Dataset`, what kind of object do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netCDF4._netCDF4.Variable"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No surprise there. And how are the data in this variable represented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude.datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 32-bit floating-point numbers. We also saw, but might not have noticed, this when we printed `latitude`, above: Note the `float32` designation in the second line. Similarly, all the other data shown above can be extracted with more targeted queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latitude of cell center in EASE-Grid-2.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude.long_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-90.,  90.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude.valid_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 720)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract metadata that we could otherwise compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518400"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are shorthand for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latitude.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518400"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude.shape[0] * latitude.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with our `Dataset`, we can look at all the public attributes and methods of our `Variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assignValue',\n",
       " 'chunking',\n",
       " 'datatype',\n",
       " 'delncattr',\n",
       " 'dimensions',\n",
       " 'dtype',\n",
       " 'endian',\n",
       " 'filters',\n",
       " 'getValue',\n",
       " 'get_var_chunk_cache',\n",
       " 'getncattr',\n",
       " 'group',\n",
       " 'long_name',\n",
       " 'mask',\n",
       " 'name',\n",
       " 'ncattrs',\n",
       " 'ndim',\n",
       " 'renameAttribute',\n",
       " 'scale',\n",
       " 'set_auto_mask',\n",
       " 'set_auto_maskandscale',\n",
       " 'set_auto_scale',\n",
       " 'set_var_chunk_cache',\n",
       " 'setncattr',\n",
       " 'setncatts',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'standard_name',\n",
       " 'units',\n",
       " 'valid_range']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: not re.match('^_.*', x), dir(latitude)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instances of the `Variable` class (like our `latitude` object) from `netCDF``latitude` variable behave like multidimensional arrays, similar to NumPy's `ndarray`. So, we can access elements with the familiar `[]` bracket notation. Since we know that `latitude` is 720x720, as we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we look at the first row in the `latitude` array, its length is similarly what we'd expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latitude[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python is zero-indexed like C, and unlike Fortran, so valid indices range from 0 to 719."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the `time` variable from our dataset and examine it. (Note that we can view output from commands other than the last one in a cell by explicitly using Python's `print` command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "int32 time(time)\n",
      "    calendar: gregorian\n",
      "    axis: T\n",
      "    units: days since 1998-12-31\n",
      "    long_name: time\n",
      "    standard_name: time\n",
      "unlimited dimensions: time\n",
      "current shape = (1,)\n",
      "filling off\n",
      "\n",
      "4749\n"
     ]
    }
   ],
   "source": [
    "time = dataset.variables['time']\n",
    "print(time)\n",
    "print(time[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this dataset's data starts 4749 days after 1998-12-31 on the Gregorian calendar. Handy! (Not really.)\n",
    "\n",
    "Out of curiosity, let's check that the `longitude` variable's shape conforms to that of `latitude`, as we'd hope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 longitude(rows, cols)\n",
       "    _FillValue: -999.0\n",
       "    long_name: longitude of cell center in EASE-Grid-2.0\n",
       "    units: degrees_east\n",
       "    valid_range: [-180.  180.]\n",
       "    standard_name: longitude\n",
       "unlimited dimensions: \n",
       "current shape = (720, 720)\n",
       "filling off"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longitude = dataset.variables['longitude']\n",
    "longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, it does.\n",
    "\n",
    "Now let's look at one of the actual snow-cover variables which, presumably, is why we're bothering with this dataset in the first place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "int16 merged_snow_cover_extent(time, rows, cols)\n",
       "    flag_meanings: modis_microwave_ims_report_snow modis_microwave_report_snow modis_ims_report_snow microwave_ims_report_snow modis_only_reports_snow microwave_only_reports_snow ims_only_reports_snow snow_free_land permanent_ice ocean\n",
       "    flag_values: [10 11 12 13 14 15 16 20 30 40]\n",
       "    _FillValue: -99\n",
       "    comment: 10: Snow cover reported by modis_cloud_gap_filled, passive_microwave, ims, 11: Snow cover reported by modis_cloud_gap_filled, passive_microwave,  12: Snow cover reported by modis_cloud_gap_filled, ims, 13: Snow cover reported by passive_microwave, ims, 14: Snow cover reported by modis_cloud_gap_filled only, 15: Snow cover reported by passive_microwave only, 16: Snow cover reported by ims only, 20: Snow free land, 30: Permanent ice covered land, 40: Ocean\n",
       "    valid_range: [10 40]\n",
       "    coordinates: longitude latitude time\n",
       "    long_name: Merged Snow Cover Extent\n",
       "    grid_mapping: coord_system\n",
       "unlimited dimensions: time\n",
       "current shape = (1, 720, 720)\n",
       "filling off"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msce = dataset.variables['merged_snow_cover_extent']\n",
    "msce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the Merged Snow Cover Extent variable, we see that the data is in a 720x720 array (the dimensions match those of latitude and longitude, so that's good!) whose values are integers specifying snow cover information from various sources, as well as snow-free and ice-covered land, and ocean.\n",
    "\n",
    "We can pick a \"random\" array element and see its value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msce[0][360][360]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 = Ocean. Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.8417\n",
      "45.0\n"
     ]
    }
   ],
   "source": [
    "print(latitude[360][360])\n",
    "print(longitude[360][360])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty close to the north pole, in the Arctic Ocean, so seems reasonable.\n",
    "\n",
    "Let's use NumPy to convert our `msce` variable into an `ndarray` object, and get rid of that useless first dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 720)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "msce = np.array(msce)[0, :, :]\n",
    "msce.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better. Now `msce`'s dimension matches that of `latitude` and `longitude`.\n",
    "\n",
    "How much _good_ data do we have in `msce`? That is, how many data elements are there in total, and how many are set to the bad-data fill value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518400\n",
      "408052\n"
     ]
    }
   ],
   "source": [
    "print(msce.size)\n",
    "print(msce[msce != -99].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, over 20% of the data elements are set to the fill value. This sometimes happens with satellite (and other data): Quality Control (QC) algorithms determine that some observations are suspect, so they are marked as such so that further analysis can avoid depending on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting data with OpenDAP\n",
    "\n",
    "One benefit to using OpenDAP for data acess is that data can be subsetted prior to download, to avoid the transfer and storage of data one is not interested in.\n",
    "\n",
    "NSIDC's [OPeNDAP Server Dataset Access Form](http://opendap.apps.nsidc.org/opendap/DATASETS/nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc.html) for this data gives some guidance on subsetting the data. For starters, let's restrict our query to the three variables -- Latitude, Longitude, and Merged Snow Cover Extent -- that we are interested in. When we tick the checkboxes for _latitude_, _longitude_, and _merged_snow_cover_extent_, the URL shown in the _Data URL_ field is updated to:\n",
    "\n",
    "`http://opendap.apps.nsidc.org:80/opendap/DATASETS/nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc?latitude[0:1:719][0:1:719],longitude[0:1:719][0:1:719],merged_snow_cover_extent[0:1:0][0:1:719][0:1:719]`\n",
    "\n",
    "Let's perform our query and data again with this URL and check the variables we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude\n",
      "longitude\n",
      "merged_snow_cover_extent\n"
     ]
    }
   ],
   "source": [
    "url = ('http://opendap.apps.nsidc.org:80/opendap/DATASETS/'\n",
    "       'nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc?'\n",
    "       'latitude[0:1:719][0:1:719],'\n",
    "       'longitude[0:1:719][0:1:719],'\n",
    "       'merged_snow_cover_extent[0:1:0][0:1:719][0:1:719]'\n",
    ")\n",
    "dataset = netCDF4.Dataset(url)\n",
    "for variable in dataset.variables:\n",
    "    print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we had ten variables; now we have only three. Nice.\n",
    "\n",
    "Let's say we're only interested in snow cover in Iceland. Let's subset the data geographically as well. The [OPeNDAP Server Dataset Access Form](http://opendap.apps.nsidc.org/opendap/DATASETS/nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc.html) gives us options for constraining the variables, but expects us to do so by row and column. Iceland lies between about 12 to 25 degrees west, and 63 to 67 degrees north. Let's see which rows and columns in our Dataset fall within those bounds:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yo! Is there a nicer way to do the thing below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows 453:476\n",
      "cols 310:338\n"
     ]
    }
   ],
   "source": [
    "latitude = np.array(dataset.variables['latitude'])\n",
    "longitude = np.array(dataset.variables['longitude'])\n",
    "minrow = 720\n",
    "maxrow = -1\n",
    "mincol = 720\n",
    "maxcol = -1\n",
    "for row in range(0, 720):\n",
    "    for col in range(0, 720):\n",
    "        a = latitude[row][col]\n",
    "        b = longitude[row][col]\n",
    "        if a >= 63 and a <= 67 and b >= -25 and b <= -12:\n",
    "            minrow = min(minrow, row)\n",
    "            maxrow = max(maxrow, row)\n",
    "            mincol = min(mincol, col)\n",
    "            maxcol = max(maxcol, col)\n",
    "print('rows %d:%d' % (minrow, maxrow))\n",
    "print('cols %d:%d' % (mincol, maxcol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add contraints our OpenDAP URL to select just the rows and columns that we think correspond to Iceland. The OpenDAP constraints are given in `lower_bound:stride:upper_bound` form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_CLASSIC data model, file format DAP2):\n",
       "    Conventions: CF-1.6\n",
       "    Metadata_Conventions: CF-1.6, Unidata Dataset Discovery v1.0, GDS v2.0\n",
       "    standard_name_vocabulary: CF Standard Name Table (v22, 12 February 2013)\n",
       "    id: nhtsd25e2_20120101_v01r01.nc\n",
       "    naming_authority: gov.nasa.eosdis\n",
       "    reference: http://dx.doi.org/10.5067/MEASURES/CRYOSPHERE/nsidc-0530.001\n",
       "    metadata_link: http://nsidc.org/api/metadata?id=nsidc-0530\n",
       "    title: MEaSUREs Northern Hemisphere Terrestrial Snow Cover Extent Daily 25km EASE-Grid 2.0\n",
       "    product_version: v01r01\n",
       "    summary: This NASA MEaSUREs Earth System Data Record (ESDR) merges daily Northern Hemisphere snow cover extents over land derived from three independently produced sources.  Variables include snow cover extent from the Interactive Multisensor Snow and Ice Mapping System (IMS), a gap-filled snow extent product derived from the Moderate Resolution Imaging Spectroradiometer (MODIS), and a gap-filled snow extent product derived from the Special Sensor Microwave/Imager (SSMI) and Special Sensor Microwave Imager/Sounder (SSMIS).  The NSIDC Land-Ocean-Coast-Ice (LOCI) mask derived from BU-MODIS land cover data is consistently applied to each variable.  Data are in a Northern Hemisphere equal area projection at 25 km resolution, and are contained in netCDF files spanning from January 1, 1999 to December 31, 2012.\n",
       "    keywords: EARTH SCIENCE > CRYOSPHERE > SNOW/ICE > SNOW COVER, EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > SNOW/ICE > SNOW COVER\n",
       "    keywords_vocabulary: NASA Global Change Master Directory (GCMD) Earth Science Keywords, Version 8.0\n",
       "    platform: NOAA POES (Polar Orbiting Environmental Satellites), DMSP (Defense Meteorological Satellite Program), GOES (Geostationary Operational Environmental Satellite), METEOSAT, GMS (Japan Geostationary Meteorological Satellite), METOP, TERRA > Earth Observing System TERRA (AM-1), AQUA > Earth Observing System AQUA\n",
       "    sensor: VISSR > Visible and Infrared Spin Scan Radiometer, VAS > VISSR Atmospheric Sounder, MODIS > Moderate-Resolution Imaging Spectroradiometer, AMSU-B > Advanced Microwave Sounding Unit-B, AMSR-E > Advanced Microwave Scanning Radiometer-EOS, SSMI > Special Sensor Microwave/Imager, SSMIS > Special Sensor Microwave Imager/Sounder, VIIRS > Visible-Infrared Imager-Radiometer Suite\n",
       "    cdm_data_type: Grid\n",
       "    source: ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02156/24km/, ftp://sidads.colorado.edu/pub/DATASETS/nsidc0001_polar_stereo_tbs/, ftp://n5eil01u.ecs.nsidc.org/SAN/MOST/MOD10C1.005/\n",
       "    date_created: 2015-06-10T02:58:06Z\n",
       "    institution: Center for Environmental Prediction, Rutgers University\n",
       "    geospatial_lat_units: degrees_north\n",
       "    geospatial_lon_units: degrees_east\n",
       "    geospatial_lat_min: 0\n",
       "    geospatial_lat_max: 90\n",
       "    geospatial_lon_min: -180\n",
       "    geospatial_lon_max: 180\n",
       "    spatial_resolution: 25 km\n",
       "    license: No restrictions on access or use\n",
       "    DODS_EXTRA.Unlimited_Dimension: time\n",
       "    dimensions(sizes): time(1), cols(29), rows(24)\n",
       "    variables(dimensions): float32 \u001b[4mlatitude\u001b[0m(rows,cols), float32 \u001b[4mlongitude\u001b[0m(rows,cols), int16 \u001b[4mmerged_snow_cover_extent\u001b[0m(time,rows,cols)\n",
       "    groups: "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = ('http://opendap.apps.nsidc.org:80/opendap/DATASETS/'\n",
    "       'nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc?'\n",
    "       'latitude[453:1:476][310:1:338],'\n",
    "       'longitude[453:1:476][310:1:338],'\n",
    "       'merged_snow_cover_extent[0:1:0][453:1:476][310:1:338]'\n",
    ")\n",
    "dataset = netCDF4.Dataset(url)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the line `dimensions(sizes): time(1), cols(29), rows(24)`: 24 rows and 29 columns, which corresponds to our request. This is a lot less data than we were retrieving before!\n",
    "\n",
    "In Module 3, we'll display this geolocated data and see if we really got what we asked for."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
